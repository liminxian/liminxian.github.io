<p>Xiangbo Shu&#39;s Homepage</p>

<table border="0" width="100%">
	<tbody>
		<tr>
			<td width="300">

				<table>
					<tbody>
						<tr>
							<td>
								<a href="images/xiangboshu.jpg"><img src="images/xiangboshu.jpg" height="270" alt="Xiangbo Shu photo" border="1" class="fr-fic fr-dib"></a>
							</td>
						</tr>
					</tbody>
				</table>
			</td>
			<td width="15">
				<br>
			</td>
			<td>
				<br>
			</td>
			<td>

				<table border="0" width="100%">
					<tbody>
						<tr height="20">
							<td colspan="2">
								<br>
							</td>
						</tr>
						<tr height="60">
							<td>

								<p class="caption">Xiangbo Shu, 舒祥波
									<br>
									<br>
								</p>

								<p class="content">Assistant Professor, Ph.D.</p>

								<p class="content">Intelligent Media Analysis Group (IMAG)</p>

								<p class="content">School of Computer Science and Engineering</p>

								<p class="content">Nanjing University of Science and Technology</p>
							</td>
						</tr>
						<tr height="60">
							<td>

								<table border="0" width="100%">
									<tbody>
										<tr height="20">
											<td width="55">

												<p class="content"><strong>Email:&nbsp;</strong></p>
												<br>
											</td>
											<td>

												<p class="content">shuxb [AT] njust [DOT] edu [DOT] cn</p>
												<br>
											</td>
										</tr>
									</tbody>
								</table>
							</td>
						</tr>
						<tr height="40">
							<td>

								<p class="margin">&nbsp;</p>

								<p class="content"><strong><a href="https://scholar.google.com/citations?user=FQfcm5oAAAAJ&hl=zh-CN&oi=ao">Google scholar</a></strong> | <strong><a href="https://dblp.uni-trier.de/pers/hd/s/Shu:Xiangbo">DBLP</a></strong> |<strong><a href="#sect-publications">Papers</a></strong> | <strong><a href="#sect-awards">Awards</a></strong></p><strong>&nbsp;<!-- <p class="content"><strong><a href="#sect-publications">Papers</a></strong> | <strong><a href="#sect-awards">Awards</a></strong> -->&nbsp;</strong>
							</td>
						</tr>
						<tr height="20">
							<td colspan="2">
								<br>
							</td>
						</tr>
					</tbody>
				</table>
			</td>
		</tr>
	</tbody>
</table>

<p class="margin">&nbsp;</p>

<table border="0">
	<tbody>
		<tr>
			<td width="900">

				<p align="justify" class="content">I am currently an Assistant Professor in <strong><a class="caption-2" href="https://imag-njust.net/" rel="nofollow" target="_blank">Intelligent Media Analysis Group (IMAG)</a></strong>, at School of Computer Science and Engineering, Nanjing University of Science and Technology, China. I received the Ph.D. degree from School of Computer Science and Engineering, Nanjing University of Science and Technology, China, under the supervisor Prof. <strong><a class="caption-2" href="https://sites.google.com/site/tangjh1981/" rel="nofollow" target="_blank">Jinhui Tang</a></strong>, a leader professor of Intelligent Media Analysis Group (IMAG). From Aug. 2014 to Aug. 2015, I am also an visiting scholar supervised by Prof. <strong><a class="caption-2" href="https://www.ece.nus.edu.sg/stfpage/eleyans/" rel="nofollow" target="_blank">Shuicheng Yan</a></strong> in <strong><a class="caption-2" href="http://www.lv-nus.org/" rel="nofollow" target="_blank">Learning and Vision Research Group</a></strong> at the Department of Electrical and Computer Engineering, National University of Singapore.</p>
				<br>
				<!--
				<p align="justify" class="content"> My Ph.D. was supported by a <strong><a href="https://research.fb.com/fellows/zhu-jun-yan/" target="_blank" rel="nofollow" class="caption-2">Facebook Fellowship</a></strong>.
					My dissertation won the 2018 ACM SIGGRAPH Outstanding Doctoral Dissertation <strong><a href="https://www.siggraph.org/outstanding-doctoral-dissertation-award-jun-yan-zhu" target="_blank" rel="nofollow" class="caption-2">Award</a></strong> from SIGGRAPH
					and 2017-18 David J. Sakrison Memorial <strong><a href="https://www2.eecs.berkeley.edu/Students/Awards/17/" target="_blank" rel="nofollow" class="caption-2">Prize</a></strong> for outstanding doctoral research from the UC Berkeley EECS Department.</p>
        <br>
		-->
				<!--
	<p align="justify" class="content">I received my B.E in Computer Sciences from Tsinghua University in 2012, where I worked with Prof. <strong><a href="http://pages.ucsd.edu/~ztu/" target="_blank" rel="nofollow" class="caption-2">Zhuowen Tu</a></strong> and Dr. <strong><a href="http://research.microsoft.com/en-us/people/echang/" target="_blank" rel="nofollow" class="caption-2">Eric Chang</a></strong> at Microsoft Research Asia and worked with
			Prof. <strong><a href="http://cg.cs.tsinghua.edu.cn/" target="_blank" rel="nofollow" class="caption-2">Shi-Min Hu</a></strong> at Tsinghua's Graphics Group.</p>
			-->
			</td>
		</tr>
	</tbody>
</table>
<!-- 
<br>
<p id="sect-events" class="title-large">News & Events</p>
<p class="content">PyTorch <strong> <a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix">code</a></strong> for CycleGAN and pix2pix (with PyTorch 0.4+).</p>
<p class="content">CycleGAN/pix2pix <strong><a href="https://blog.udacity.com/2018/08/deep-learning-udacity-evolves.html">lecture</a></strong> at Udacity deep learning course.</p>
<p class="content">SIGGRAPH Asia 2018, Technical Papers Committee member.<p>
<p class="content">CVPR 2018 <strong><a href="https://sites.google.com/view/cvpr2018tutorialongans/">Tutorial</a></strong> on Generative Adversarial Networks.</p>
<p class="content">ICCV 2017 <strong><a href="https://sites.google.com/view/iccv-2017-gans/">Tutorial</a></strong> on Generative Adversarial Networks.</p>
<p class="content">ICML 2017 <strong><a href="http://icmlviz.github.io/">Workshop</a></strong>  on Visualization for Deep Learning.</p>
<p class="content">SIGGRAPH Asia 2014 invited <strong><a href="http://kevinkaixu.net/courses/ddvc.html">Course</a></strong> on Data-Driven Visual Computing.</p>
<br>
-->

<p class="title-large" id="sect-Interests">Research Interests</p>

<p class="content">Computer Vision, Multimedia Computing, Deep Learning</p>

<p class="content">Applications: Human Analysis, Face Analysis, Social Multimedia</p>

<p>
	<br>
</p>

<p class="title-large" id="sect-awards">Awards</p>

<p class="content">2017 Excellent Doctoral Dissertation of Chinese Association for Artificial Intelligence (CAAI)</p>

<p class="content">2017 Excellent Doctoral Dissertation of Jiangsu Province, China</p>

<p class="content">2017 Excellent Doctoral Dissertation of Jiangsu Computer Society, China</p>

<p class="content">2017 Excellent Doctoral Dissertation of Nanjing University of Science and Technology, China</p>

<p class="content">2016 MMM 2016 Best Student Paper</p>

<p class="content">2015 ACM multidedia 2015 Best Paper Runner-up</p>

<p class="content">2015 China National Scholarship</p>

<p class="content">2015 ACM MM 2015 Travel Grant</p>

<p>
	<br>
</p>

<p class="title-large" id="sect-publications">Selected Publications (<a href="https://shuxb104.github.io/paper_list.html">Full list</a>)</p>
<!-- 
<table border="0">
  <tbody><tr>
    <td width="140"><img src="images/cycada.jpg" border="1"width="210"></td>
    <td width="20"></td>
    <td valign="middle" width="800">
			<p class="content"><strong> CyCADA: Cycle-Consistent Adversarial Domain Adaptation</strong></p>
      <p class="content"><a href="https://people.eecs.berkeley.edu/~jhoffman/">Judy Hoffman</a>, <a href="https://github.com/erictzeng">Eric Tzeng</a>, <a href="https://taesung.me/">Taesung Park</a>, Jun-Yan Zhu, <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>, <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>, and <a href="http://people.eecs.berkeley.edu/~pathak/">Trevor Darrell</a></p>
      <p class="content">In International Conference on Machine Learning (<strong>ICML</strong>), 2018</p>
	 <p class="margin-small">&nbsp;</p>
	   <p class="content">
     <strong><a href="https://arxiv.org/abs/1711.03213">Paper</a></strong> |
		 <strong><a href="https://github.com/jhoffman/cycada_release">Code</a></strong> |
			<strong><a href="projects/cycada/cycada.txt">BibTex</a></strong> <br>
		</p>
      </tr>
</tbody></table>
-->

<table border="0">
	<tbody>
		<tr>
			<!-- <td width="140"><a href="https://tcwang0509.github.io/pix2pixHD/"><img src="images/vid2vid.gif" border="1"width="120"></a></td> -->
			<td width="125"><img src="images/2018pami.jpg" border="1" width="120" class="fr-fic fr-dib"></td>
			<td width="20">
				<br>
			</td>
			<td valign="middle" width="800">

				<p class="content"><strong>Personalized Age Progression with Bi-level Aging Dictionary Learning</strong></p>

				<p class="content"><strong>Xiangbo Shu</strong>, Jinhui Tang, Zechao Li, Hanjiang Lai, Liyan Zhang, Shuicheng Yan</p>

				<p class="content">IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018</p>

				<p class="margin-small">&nbsp;</p>

				<p class="content"><strong><a href="https%3A">PDF</a></strong> | <strong><a href="https%3A">BibTex</a></strong></p>
			</td>
		</tr>
	</tbody>
</table>

<table border="0">
	<tbody>
		<tr>
			<td width="125"><img src="images/2017pami.jpg" border="1" width="120" class="fr-fic fr-dib"></td>
			<td width="20">
				<br>
			</td>
			<td valign="middle" width="800">

				<p class="content"><strong>Tri-Clustered Tensor Completion for Social-Aware Image Tag Refinement</strong></p>

				<p class="content">Jinhui Tang, <strong>Xiangbo Shu</strong>, Guo-Jun Qi, Zechao Li, Meng Wang, Shuicheng Yan, Ramesh Jain</p>

				<p class="content">IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018</p>

				<p class="margin-small">&nbsp;</p>

				<p class="content"><strong><a href="https%3A">PDF</a></strong> | <strong><a href="https%3A">BibTex</a></strong></p>
			</td>
		</tr>
	</tbody>
</table>

<table border="0">
	<tbody>
		<tr>
			<td width="125"><img src="images/2018csvt.jpg" border="1" width="120" class="fr-fic fr-dib"></td>
			<td width="20">
				<br>
			</td>
			<td valign="middle" width="800">

				<p class="content"><strong>Image Classification with Tailored Fine-Grained Dictionaries</strong></p>

				<p class="content"><strong>Xiangbo Shu</strong>, Liyan Zhang, Jinhui Tang, Guo-Sen Xie, Shuicheng Yan</p>

				<p class="content">IEEE Transactions on Circuits and Systems for Video Technology, 2018</p>

				<p class="margin-small">&nbsp;</p>

				<p class="content"><strong><a href="https%3A">PDF</a></strong> | <strong><a href="https%3A">BibTex</a></strong></p>
			</td>
		</tr>
	</tbody>
</table>

<table border="0">
	<tbody>
		<tr>
			<td width="125"><img src="images/2016tomm.jpg" border="1" width="120" class="fr-fic fr-dib"></td>
			<td width="20">
				<br>
			</td>
			<td valign="middle" width="500">

				<p class="content"><strong>Generalized Deep Transfer Networks for Knowledge Propagation in Heterogeneous Domains</strong></p>

				<p class="content">Jinhui Tang, <strong>Xiangbo Shu*</strong>, Zechao Li, Guo-Jun Qi, Jingdong Wang</p>

				<p class="content">ACM Transactions on Multimedia Computing, Communications, and Applications, 2016</p>

				<p class="margin-small">&nbsp;</p>

				<p class="content"><strong><a href="https%3A">PDF</a></strong> | <strong><a href="https%3A">BibTex</a></strong></p>
			</td>
		</tr>
	</tbody>
</table>

<table border="0">
	<tbody>
		<tr>
			<td width="125"><img src="images/2016mmm.jpg" border="1" width="120" class="fr-fic fr-dib"></td>
			<td width="20">
				<br>
			</td>
			<td valign="middle" width="800">

				<p class="content"><strong>Computational Face Reader</strong></p>

				<p class="content"><strong>Xiangbo Shu</strong>, Jinhui Tang, Guo-Jun Qi, Zechao Li, Yu-Gang Jiang and Shuicheng Yan</p>

				<p class="content">International Conference on MultiMedia Modeling (MMM), 2016 (Best Student Paper)</p>

				<p class="margin-small">&nbsp;</p>

				<p class="content"><strong><a href="https%3A">PDF</a></strong> | <strong><a href="https%3A">BibTex</a></strong></p>
			</td>
		</tr>
	</tbody>
</table>

<table border="0">
	<tbody>
		<tr>
			<td width="125"><img src="images/2015mm.jpg" border="1" width="120" class="fr-fic fr-dib"></td>
			<td width="20">
				<br>
			</td>
			<td valign="middle" width="800">

				<p class="content"><strong>Weekly-Shared Deep Transfer Networks for Heterogeneous-Domain Knowledge Propagation</strong></p>

				<p class="content"><strong>Xiangbo Shu</strong>, Guo-Jun Qi, Jinhui Tang, Jingdong Wang</p>

				<p class="content">ACM Multimedia, 2015 (Best Paper Runner-up)</p>

				<p class="margin-small">&nbsp;</p>

				<p class="content"><strong><a href="https%3A">PDF</a></strong> | <strong><a href="https%3A">BibTex</a></strong></p>
			</td>
		</tr>
	</tbody>
</table>

<table border="0">
	<tbody>
		<tr>
			<td width="125"><img src="images/2015iccv.jpg" border="1" width="120" class="fr-fic fr-dib"></td>
			<td width="20">
				<br>
			</td>
			<td valign="middle" width="800">

				<p class="content"><strong>Personalized Age Progression with Aging Dictionary</strong></p>

				<p class="content"><strong>Xiangbo Shu</strong>, Jinhui Tang, Hanjiang Lai, Luoqi Liu, Shuicheng Yan</p>

				<p class="content">IEEE International Conference on Computer Vision (ICCV), 2015</p>

				<p class="margin-small">&nbsp;</p>

				<p class="content"><strong><a href="https%3A">PDF</a></strong> | <strong><a href="https%3A">BibTex</a></strong></p>
			</td>
		</tr>
	</tbody>
</table>

<p>
	<br>
</p>
<!--
<p id="sect-software" class="title-large">Software</p>
<p class="content"><strong><a href="https://github.com/NVIDIA/vid2vid">vid2vid</a></strong>: High-resolution (e.g., 2048x1024) photorealistic video-to-video translation.</p>
<p class="content"><strong><a href="https://github.com/jhoffman/cycada_release">CYCADA</a></strong>: Pytorch implementation of cycle-consistent adversarial domain adaptation.</p>
<p class="content"><strong><a href="https://github.com/NVIDIA/pix2pixHD">pix2pixHD</a></strong>: 2048x1024 image synthesis with conditional GANs.</p>
<p class="content"><strong><a href="https://github.com/junyanz/BicycleGAN">BicycleGAN</a></strong>: multimodal image-to-image translation.</p>
<p class="content"><strong><a href="https://github.com/junyanz/interactive-deep-colorization">Interactive Deep Colorization</a></strong>:  real-time interface for user-guided colorization.</p>
<p class="content"><strong><a href="https://github.com/richzhang/colorization-pytorch">PyTorch Colorization</a></strong>: PyTorch code for training interactive colorization models.</p>
<p class="content"><strong><a href="https://github.com/junyanz/light-field-video">Light Field Video</a></strong>: light field video applications (e.g. video refocusing, changing aperture and view).</p>
<p class="content"><strong><a href="https://github.com/junyanz/CycleGAN">CycleGAN</a></strong>: Torch implementation for learning an image-to-image translation without input-output pairs.</p>
<p class="content"><strong><a href="https://github.com/phillipi/pix2pix">pix2pix</a></strong>: Torch implementation for learning a mapping from input images to output images.</p>
<p class="content"><strong><a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix">pytorch CycleGAN & pix2pix</a></strong>: PyTorch implementation for both unpaired and paired image-to-image translation.</p>
<p class="content"><strong><a href="https://github.com/junyanz/iGAN">iGAN</a></strong>: a deep learning software that easily generates images with a few brushstrokes.</p>
<p class="content"><strong><a href="https://github.com/junyanz/RealismCNN">RealismCNN</a></strong>: code for predicting and improving visual realism in composite images.</p>
<p class="content"><strong><a href="https://github.com/junyanz/MCILBoost">MCILBoost</a></strong>: a boosting-based Multiple Instance Learning (MIL) software.</p>
<p class="content"><strong><a href="https://github.com/junyanz/MirrorMirror">MirrorMirror</a></strong>: an expression training App that helps users mimic their own expressions.</p>
<p class="content"><strong><a href="https://github.com/junyanz/SelectGoodFace">SelectGoodFace</a></strong>: a program for selecting attractive/serious portraits from a personal photo collection.</p>
<p class="content"><strong><a href="https://github.com/junyanz/FaceDemo">FaceDemo</a></strong>: a simple 3D face alignment and warping demo.</p>
-->
<!--
<br>
<p id="sect-talks" class="title-large">Talks</p>
<p class="content"><strong><a href="https://youtu.be/MkluiD2lYCc?t=1h16m58s">Learning to Generate Images</a></strong></p>
<p class="content">SIGGRAPH Dissertation Award Talk (2018)</p>

<p class="content"><strong><a href="http://efrosgans.eecs.berkeley.edu/CVPR18_slides/CycleGAN.pptx">Unpaired Image-to-Image Translation</a></strong></p>
<p class="content">CVPR Tutorial on GANs (2018)</p>

<p class="content"><strong><a href="talks/talk_natural_photos.pptx">Learning to Synthesize and Manipulate Natural Photos</a></strong></p>
<p class="content">MIT CSAIL, HKUST CSE Departmental Seminar, ICCV Tutorial on GANs, O'Reilly AI, AI with the best, Y Conf, DEVIEW, ODSC West (2017)</p>

<p class="content"><strong><a href="talks/image_translation.pptx">On Image-to-Image Translation</a></strong></p>
<p class="content">Stanford, MIT CSAIL, Facebook, CUHK, SNU (2017)</p>

<p class="content"><strong><a href="talks/ideepcolor.pptx">Interactive Deep Colorization</a></strong></p>
<p class="content">SIGGRAPH, NVIDIA Innovation Theater, Global AI Hackathon (2017)</p>

<p class="content"><strong><a href="talks/manipulation_synthesis_junyanz.pptx">Visual Manipulation and Synthesis on the Natural Image Manifold</a></strong></p>
<p class="content">Facebook, MSR, Berkeley BAIR, THU, ICML workshop "Visualization for Deep Learning" (2016)</p>

<p class="content"><strong><a href="http://efrosprojects.eecs.berkeley.edu/mirrormirror/mirrormirror_slides.pptx">Mirror Mirror: Crowdsourcing Better Portraits</a></strong></p>
<p class="content">SIGGRAPH Asia (2014)</p>
<p class="content"><strong><a href="talks/siga14_course_ddvc_junyanz.pdf">What Makes Big Visual Data Hard?</a></strong></p>
<p class="content">SIGGRAPH Asia invited course &quot;Data-Driven Visual Computing&quot; (2014)</p>
<p class="content"><strong><a href="http://efrosprojects.eecs.berkeley.edu/averageExplorer/averageExplorer_slides.pptx">AverageExplorer: Interactive Exploration and Alignment of Visual Data Collections</a></strong></p>
<p class="content">SIGGRAPH (2014)</p>
<p class="content"><strong><a href="talks/wsl_slides.pptx">Discovering Objects and Harvesting Visual Concepts via Weakly Supervised Learning</a></strong></p>
<p class="content"> Berkeley Visual Computing Lab (2014)</p>
<br>
-->

<p class="title-large" id="sect-talks">Academic Services</p>
<div>

	<h4 style="color:rgb(51,51,51);margin:1.5em 0px 1em;font-family:Trebuchet MS,arial,sans-serif;">
		<a name="TOC-Associate-Editors:"></a>Associate Editors:</h4>

	<h4>
		<a name="TOC-KSII-Transactions-on-Internet-and-Information-Systems-since-2018"></a>
		<div style="color:rgb(68,68,68);font-family:Verdana,Helvetica,Arial,sans-serif;font-size:13.3333px;font-weight:normal;">
			<br>
		</div>
		<div style="color:rgb(68,68,68);font-weight:normal;">

			<ul>
				<li>KSII Transactions on Internet and Information Systems, since 2018</li>
			</ul>
		</div>
	</h4>

	<h4>
		<a name="TOC-Program-Committee-Member:"></a>Program Committee Member:</h4>
</div>
<div>

	<ul>
		<li><span style="line-height:20.02px;background-color:rgb(255,255,255);">Neural Information Processing Systems (</span><span style="line-height:20.02px;background-color:rgb(255,255,255);">NIPS</span><span style="line-height:20.02px;background-color:rgb(255,255,255);">) , 2018</span></li>
		<li>International Conference on Computer Vision (ICCV), 2017</li>
		<li>ACM International Conference on Multimedia (MM: long paper, short paper), 2016-2018</li>
	</ul>
</div>

<p><span lang="EN-US">R</span><span lang="EN-US">eviewer for Journals:</span></p>

<ul>
	<li>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</li>
	<li>ACM Transactions on Knowledge Discovery from Data (TKDD)</li>
	<li>IEEE Transactions on Knowledge and Data Engineering (TKDE)</li>
	<li><span style="color:rgb(0,0,0);line-height:1.4;">IEEE Transactions on Multimedia (TMM)</span></li>
	<li>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
	<li>Pattern Recognition- Elsevier</li>
	<li>Pattern Analysis and Applications - Springer</li>
	<li>Neurocomputing - Elsevier</li>
	<li>Multimedia Tools and Applications- Springer</li>
	<li>Pattern Recognition Letters - Elsevier</li>
</ul>

<h3>
	<a name="TOC-Links"></a>
</h3>

<p class="title-large" id="sect-talks">Links</p>

<p class="margin-small">&nbsp;</p>

<p class="content"><strong><a href="https://sites.google.com/site/tangjh1981/">Jinhui Tang</a></strong> | <strong><a href="http://www.eecs.ucf.edu/~gqi/">Guo-Jun Qi</a></strong>| <strong><a href="%09%20https%3A//www.ece.nus.edu.sg/stfpage/eleyans/">Shuicheng Yan</a></strong>| <strong><a href="https://sites.google.com/site/zcliustc/">Zechao Li</a></strong> | <strong><a href="http://research.microsoft.com/en-us/um/people/jingdw/">Jingdong Wang</a></strong> | <strong><a href="http://www.yugangjiang.info/">Yu-Gang Jiang</a></strong></p>
<!-- <p id="sect-misc" class="title-large">MISC</p>
<p class="content"><strong><a href="imgs/pet.JPG">Photo</a></strong> of my cat Aquarius and my dog Arya.</p> -->
<div style="display:none;">
	<!-- GoStats JavaScript Based Code -->
	<!-- <a target="_blank" title="web page statistics from GoStats"
href="http://gostats.com"> --></div>
<!--
<img alt="web page statistics from GoStats"
src="http://c3.gostats.com/bin/count/a_390583/t_4/i_1/z_0/show_hits/counter.png"
style="border-width:0" />
</a>
-->
<!-- End GoStats JavaScript Based Code -->
