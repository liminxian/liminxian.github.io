
<html><head>
<title>Xiangbo Shu's Homepage</title>
<style type="text/css">
body {
	margin-top: 30px;
	margin-bottom: 30px;
	margin-left: 100px;
	margin-right: 100px;
}
p {
	margin-top: 0px;
	margin-bottom: 0px;
}

.caption {
	font-size: 34px;
	font-weight: normal;
	color: #000;
	font-family: Constantia, "Lucida Bright", "DejaVu Serif", Georgia, serif;
}
.caption-1 {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
}
.caption-2 {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
	font-weight: bold;
	color: #990000;
}
.caption-3 {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
	font-weight: bold;
	color: #F00;
}

.caption-4 {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
	color: #990000;
}
.content {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
	text-align: justify;
}
.content a {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
	color: #000;
}
.content strong a {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
	color: #990000;
}
.title-small {
	font-size: 20px;
	font-family: Georgia, "Times New Roman", Times, serif;
	font-weight: bold;
	color: #F90;
}
.title-large {
	font-size: 28px;
	font-family: Georgia, "Times New Roman", Times, serif;
	font-weight: bold;
	color: #000;
}
.margin {
	font-size: 10px;
	line-height: 10px;
}
.margin-small {
	font-size: 5px;
	line-height: 5px;
}
.margin-large {
	font-size: 16px;
	line-height: 16px;
}
a:link {
	text-decoration: none;
}
a:visited {
	text-decoration: none;
}
content a:link {
	text-decoration: none;
}
content a:visited {
	text-decoration: none;
}
a:hover {
	text-decoration: underline;
}
a:active {
	text-decoration: underline;
	color: #000000;
	font-family: Tahoma, Geneva, sans-serif;
}
strong a:active {
	text-decoration: underline;
	color: #000000;
}
img
{
 border-color: black;
}


</style>
<meta http-equiv="Content-Type" content="text/html; charset=gbk"></head>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-53682931-1', 'auto');
  ga('send', 'pageview');

</script>

<body>

<table border="0" width="100%">
  <tbody>

    <tr>

    <td width="300"><table>
			<tr><td>
			<a href="images/ShuXB.png"><img src="images/ShuXB.png"  height="270" alt="Xiangbo Shu photo" border=1></td></tr>
			</table></td>
    <td width="5"></td>
    <td></td>
    <td><table border="0" width="100%">
      <tbody><tr height="20">
        <td colspan="2"></td></tr>


         <tr height="60">
        <td>
           <p class="caption">Xiangbo Shu, 舒祥波<br><br></p>
           <p class="content">Assistant Professor, Ph.D.</p>
            <p class="content">Intelligent Media Analysis Group (IMAG)</p>
           <p class="content">School of Computer Science and Engineering</p>
            <p class="content">Nanjing University of Science and Technology</p>
        </td>
      </tr>

      <tr height="60">
        <td><table border="0" width="100%">
          <tbody><tr height="20">
            <td width="55">

              <p class="content"><strong>Email: </strong></p><br></td>
            <td>
              <p class="content">shuxb [AT] njust [DOT] edu [DOT] cn</p><br></td>
          </tr>

        </tbody></table></td>
      </tr>

      <tr height="40">
        <td>
          <p class="margin">&nbsp;</p>
          <p class="content"><strong><a href="https://scholar.google.com/citations?user=FQfcm5oAAAAJ&hl=zh-CN&oi=ao">Google scholar</a></strong> | <strong><a href="https://dblp.uni-trier.de/pers/hd/s/Shu:Xiangbo">DBLP</a></strong> |<strong><a href="#sect-publications">Papers</a></strong> | <strong><a href="#sect-awards">Awards</a></p>
					<!-- <p class="content"><strong><a href="#sect-publications">Papers</a></strong> | <strong><a href="#sect-awards">Awards</a></strong> -->
        </td>
      </tr>
      <tr height="20">
        <td colspan="2"></td></tr>
    </tbody></table></td>
  </tr>
</tbody></table>
<p class="margin">&nbsp;</p>

<table border="0" >
  <tbody>
    <tr>
      <td width="900"> <p align="justify" class="content">I am currently  an Assistant Professor in <strong><a href="https://imag-njust.net/" target="_blank" rel="nofollow" class="caption-2">Intelligent Media Analysis Group (IMAG)</a></strong>, at School of Computer Science and Engineering, Nanjing University of Science and Technology, China. I received the Ph.D. degree from School of Computer Science and Engineering, Nanjing University of Science and Technology, China, under the supervisor Prof. <strong><a href="https://sites.google.com/site/tangjh1981/" target="_blank" rel="nofollow" class="caption-2">Jinhui Tang</a></strong>, a leader professor of Intelligent Media Analysis Group (IMAG). From Aug. 2014 to Aug. 2015, I am also an visiting scholar supervised by Prof. <strong><a href="https://www.ece.nus.edu.sg/stfpage/eleyans/" target="_blank" rel="nofollow" class="caption-2">Shuicheng Yan</a></strong> in <strong><a href="http://www.lv-nus.org/" target="_blank" rel="nofollow" class="caption-2">Learning and Vision Research Group</a></strong> at the Department of Electrical and Computer Engineering, National University of Singapore. I am the member of the IEEE, the ACM, and the CCF.</p>
				<br>
				<!--
				<p align="justify" class="content"> My Ph.D. was supported by a <strong><a href="https://research.fb.com/fellows/zhu-jun-yan/" target="_blank" rel="nofollow" class="caption-2">Facebook Fellowship</a></strong>.
					My dissertation won the 2018 ACM SIGGRAPH Outstanding Doctoral Dissertation <strong><a href="https://www.siggraph.org/outstanding-doctoral-dissertation-award-jun-yan-zhu" target="_blank" rel="nofollow" class="caption-2">Award</a></strong> from SIGGRAPH
					and 2017-18 David J. Sakrison Memorial <strong><a href="https://www2.eecs.berkeley.edu/Students/Awards/17/" target="_blank" rel="nofollow" class="caption-2">Prize</a></strong> for outstanding doctoral research from the UC Berkeley EECS Department.</p>
        <br>
		-->

    <!--
	<p align="justify" class="content">I received my B.E in Computer Sciences from Tsinghua University in 2012, where I worked with Prof. <strong><a href="http://pages.ucsd.edu/~ztu/" target="_blank" rel="nofollow" class="caption-2">Zhuowen Tu</a></strong> and Dr. <strong><a href="http://research.microsoft.com/en-us/people/echang/" target="_blank" rel="nofollow" class="caption-2">Eric Chang</a></strong> at Microsoft Research Asia and worked with
			Prof. <strong><a href="http://cg.cs.tsinghua.edu.cn/" target="_blank" rel="nofollow" class="caption-2">Shi-Min Hu</a></strong> at Tsinghua's Graphics Group.</p>
			-->
    </tr>
  </tbody>
</table>

<!-- 
<br>
<p id="sect-events" class="title-large">News &amp; Events</p>
<p class="content">PyTorch <strong> <a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix">code</a></strong> for CycleGAN and pix2pix (with PyTorch 0.4+).</p>
<p class="content">CycleGAN/pix2pix <strong><a href="https://blog.udacity.com/2018/08/deep-learning-udacity-evolves.html">lecture</a></strong> at Udacity deep learning course.</p>
<p class="content">SIGGRAPH Asia 2018, Technical Papers Committee member.<p>
<p class="content">CVPR 2018 <strong><a href="https://sites.google.com/view/cvpr2018tutorialongans/">Tutorial</a></strong> on Generative Adversarial Networks.</p>
<p class="content">ICCV 2017 <strong><a href="https://sites.google.com/view/iccv-2017-gans/">Tutorial</a></strong> on Generative Adversarial Networks.</p>
<p class="content">ICML 2017 <strong><a href="http://icmlviz.github.io/">Workshop</a></strong>  on Visualization for Deep Learning.</p>
<p class="content">SIGGRAPH Asia 2014 invited <strong><a href="http://kevinkaixu.net/courses/ddvc.html">Course</a></strong> on Data-Driven Visual Computing.</p>
<br>
-->

<p id="sect-Interests" class="title-large">Research Interests</p>
<p class="content">Computer Vision, Multimedia Computing, Deep Learning</p>
<p class="content">Applications: Human Analysis, Face Analysis, Social Multimedia</p>
<br>

<p id="sect-awards" class="title-large">Awards</p>
<p class="content">2017  Excellent Doctoral Dissertation of Chinese Association for Artificial Intelligence (CAAI)</p>
<p class="content">2017 Excellent Doctoral Dissertation of Jiangsu Province, China</p>
<p class="content">2017 Excellent Doctoral Dissertation of Jiangsu Computer Society, China</p>
<p class="content">2017 Excellent Doctoral Dissertation of Nanjing University of Science and Technology, China</p>
<p class="content">2016 Best Student Paper in MMM 2016</p>
<p class="content">2015 Best Paper Runner-up in ACM Multimedia 2015</p>
<p class="content">2015 China National Scholarship</p>
<p class="content">2015 ACM MM 2015 Travel Grant</p>
<br>



<p id="sect-publications" class="title-large">Selected Publications</p>
<!-- 
<table border="0">
  <tbody><tr>
    <td width="140"><img src="images/cycada.jpg" border="1"width="210"></td>
    <td width="20"></td>
    <td valign="middle" width="800">
			<p class="content"><strong> CyCADA: Cycle-Consistent Adversarial Domain Adaptation</strong></p>
      <p class="content"><a href="https://people.eecs.berkeley.edu/~jhoffman/">Judy Hoffman</a>, <a href="https://github.com/erictzeng">Eric Tzeng</a>, <a href="https://taesung.me/">Taesung Park</a>, Jun-Yan Zhu, <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>, <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>, and <a href="http://people.eecs.berkeley.edu/~pathak/">Trevor Darrell</a></p>
      <p class="content">In International Conference on Machine Learning (<strong>ICML</strong>), 2018</p>
	 <p class="margin-small">&nbsp;</p>
	   <p class="content">
     <strong><a href="https://arxiv.org/abs/1711.03213">Paper</a></strong> |
		 <strong><a href="https://github.com/jhoffman/cycada_release">Code</a></strong> |
			<strong><a href="projects/cycada/cycada.txt">BibTex</a></strong> <br>
		</p>
      </tr>
</tbody></table>
-->

<table border="0">
  <tbody><tr>
    <!-- <td width="140"><a href="https://tcwang0509.github.io/pix2pixHD/"><img src="images/vid2vid.gif" border="1"width="120"></a></td> -->
	 <td width="125"><img src="images/2018pami2.jpg" border="1"width="120"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><strong>Hierarchical Long Short-Term Concurrent Memory for Human Interaction Recognition</strong></p>
      <p class="content"><b>Xiangbo Shu</b>, Jinhui Tang, Guo-Jun Qi, Wei Liu, Jian Yang</p>
      <p class="content">IEEE Transactions on Pattern Analysis and Machine Intelligence (Major Revision)</p>
	   <p class="margin-small">&nbsp;</p>
	   <p class="content">
			<strong><a href="https:">PDF</a></strong> |
			<strong><a href="https:">BibTex</a></strong> <br> </p>  </tr>
</tbody></table>

<table border="0">
  <tbody><tr>
    <!-- <td width="140"><a href="https://tcwang0509.github.io/pix2pixHD/"><img src="images/vid2vid.gif" border="1"width="120"></a></td> -->
	 <td width="125"><img src="images/2018pami.jpg" border="1"width="120"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><strong>Personalized Age Progression with Bi-level Aging Dictionary Learning</strong></p>
      <p class="content"><b>Xiangbo Shu</b>, Jinhui Tang, Zechao Li, Hanjiang Lai, Liyan Zhang, Shuicheng Yan</p>
      <p class="content">IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018</p>
	   <p class="margin-small">&nbsp;</p>
	   <p class="content">
			<strong><a href="https:">PDF</a></strong> |
			<strong><a href="https:">BibTex</a></strong> <br> </p>  </tr>
</tbody></table>

<table border="0">
  <tbody><tr>
    <!-- <td width="140"><a href="https://tcwang0509.github.io/pix2pixHD/"><img src="images/vid2vid.gif" border="1"width="120"></a></td> -->
	 <td width="125"><img src="images/2018pami3.jpg" border="1"width="120"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><strong>Social Anchor-Unit Graph Regularized Tensor Completion for Large-Scale Image Retagging</strong></p>
      <p class="content">Jinhui Tang, <b>Xiangbo Shu</b>, Zechao Li, Qi Tian</p>
      <p class="content">IEEE Transactions on Pattern Analysis and Machine Intelligence (Major Revision)</p>
	   <p class="margin-small">&nbsp;</p>
	   <p class="content">
			<strong><a href="https:">PDF</a></strong> |
			<strong><a href="https:">BibTex</a></strong> <br> </p>  </tr>
</tbody></table>

<table border="0">
  <tbody><tr>
    <td width="125"><img src="images/2017pami.jpg" border="1"width="120"></td>
    <td width="20"></td>
    <td valign="middle" width="800">
			<p class="content"><strong>Tri-Clustered Tensor Completion for Social-Aware Image Tag Refinement</strong></p>
      <p class="content">Jinhui Tang, <b>Xiangbo Shu</b>, Guo-Jun Qi, Zechao Li, Meng Wang, Shuicheng Yan, Ramesh Jain</p>
      <p class="content">IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018</p>
	 <p class="margin-small">&nbsp;</p>
	   <p class="content">
     <strong><a href="https:">PDF</a></strong> |
			<strong><a href="https:">BibTex</a></strong> <br>
		</p>
      </tr>
</tbody></table>

<table border="0">
  <tbody><tr>
    <td width="125"><img src="images/2018csvt.jpg" border="1"width="120"></td>
    <td width="20"></td>
    <td valign="middle" width="800">
			<p class="content"><strong>Image Classification with Tailored Fine-Grained Dictionaries</strong></p>
      <p class="content"><b>Xiangbo Shu</b>, Liyan Zhang, Jinhui Tang, Guo-Sen Xie, Shuicheng Yan</p>
      <p class="content">IEEE Transactions on Circuits and Systems for Video Technology, 2018</p>
	 <p class="margin-small">&nbsp;</p>
	   <p class="content">
     <strong><a href="https:">PDF</a></strong> |
			<strong><a href="https:">BibTex</a></strong> <br>
		</p>
      </tr>
</tbody></table>


<table border="0">
  <tbody><tr>
    <td width="125"><img src="images/2016tomm.jpg" border="1"width="120"></td>
    <td width="20"></td>
    <td valign="middle" width="500">
			<p class="content"><strong>Generalized Deep Transfer Networks for Knowledge Propagation in Heterogeneous Domains</strong></p>
      <p class="content">Jinhui Tang, <b>Xiangbo Shu*</b>, Zechao Li, Guo-Jun Qi, Jingdong Wang</p>
      <p class="content">ACM Transactions on Multimedia Computing, Communications, and Applications, 2016</p>
	 <p class="margin-small">&nbsp;</p>
	   <p class="content">
     <strong><a href="https:">PDF</a></strong> |
			<strong><a href="https:">BibTex</a></strong> <br>
		</p>
      </tr>
</tbody></table>


<table border="0">
  <tbody><tr>
    <td width="125"><img src="images/2016mmm.jpg" border="1"width="120"></td>
    <td width="20"></td>
    <td valign="middle" width="800">
			<p class="content"><strong>Computational Face Reader</strong></p>
      <p class="content"><b>Xiangbo Shu</b>, Jinhui Tang, Guo-Jun Qi, Zechao Li, Yu-Gang Jiang and Shuicheng Yan</p>
      <p class="content">International Conference on MultiMedia Modeling (MMM), 2016 (</font><font color="#ff0000">Best Student Paper</font><font color="#000000">)</font></p>
	 <p class="margin-small">&nbsp;</p>
	   <p class="content">
     <strong><a href="https:">PDF</a></strong> |
			<strong><a href="https:">BibTex</a></strong> <br>
		</p>
      </tr>
</tbody></table>

<table border="0">
  <tbody><tr>
    <td width="125"><img src="images/2015mm.jpg" border="1"width="120"></td>
    <td width="20"></td>
    <td valign="middle" width="800">
			<p class="content"><strong>Weekly-Shared Deep Transfer Networks for Heterogeneous-Domain Knowledge Propagation</strong></p>
      <p class="content"><b>Xiangbo Shu</b>, Guo-Jun Qi, Jinhui Tang, Jingdong Wang</p>
      <p class="content">ACM Multimedia, 2015 (</font><font color="#ff0000">Best Paper Runner-up</font><font color="#000000">)</font></p>
	 <p class="margin-small">&nbsp;</p>
	   <p class="content">
     <strong><a href="https://shuxb104.github.io/paper/Weakly-Shared%20Deep%20Transfer%20Networks%20for%20Heterogeneous-Domain%20Knowledge%20Propagation.pdf">PDF</a></strong> |
			<strong><a href="https:">BibTex</a></strong> <br>
		</p>
      </tr>
</tbody></table>

<table border="0">
  <tbody><tr>
    <td width="125"><img src="images/2015iccv.jpg" border="1"width="120"></td>
    <td width="20"></td>
    <td valign="middle" width="800">
			<p class="content"><strong>Personalized Age Progression with Aging Dictionary</strong></p>
      <p class="content"><b>Xiangbo Shu</b>, Jinhui Tang, Hanjiang Lai, Luoqi Liu, Shuicheng Yan</p>
      <p class="content">IEEE International Conference on Computer Vision (ICCV), 2015</p>
	 <p class="margin-small">&nbsp;</p>
	   <p class="content">
     <strong><a href="https:">PDF</a></strong> |
			<strong><a href="https:">BibTex</a></strong> <br>
		</p>
      </tr>
</tbody></table>

<table border="0">
  <tbody><tr>
    <td width="125"><img src="images/2018mm.jpg" border="1"width="120"></td>
    <td width="20"></td>
    <td valign="middle" width="800">
			<p class="content"><strong>Participation-Contributed Temporal Dynamic Model for Group Activity Recognition </strong></p>
      <p class="content">Rui Yan, Jinhui Tang, <b>Xiangbo Shu</b>, Zechao Li, Qi Tian</p>
      <p class="content">ACM MultiMedia (MM), 2018 (Oral paper)</p>
	 <p class="margin-small">&nbsp;</p>
	   <p class="content">
     <strong><a href="https:">PDF</a></strong> |
			<strong><a href="https:">BibTex</a></strong> <br>
		</p>
      </tr>
</tbody></table>

<br>


<p id="sect-Interests" class="title-large">Teaching</p>
<p class="content">Fall 2018: Multimedia Computing </p>
<p class="content">Fall 2017: Multimedia Computing </p>
<p class="content">Fall 2016: Multimedia Computing</p>
<br>



<!--
<p id="sect-software" class="title-large">Software</p>
<p class="content"><strong><a href="https://github.com/NVIDIA/vid2vid">vid2vid</a></strong>: High-resolution (e.g., 2048x1024) photorealistic video-to-video translation.</p>
<p class="content"><strong><a href="https://github.com/jhoffman/cycada_release">CYCADA</a></strong>: Pytorch implementation of cycle-consistent adversarial domain adaptation.</p>
<p class="content"><strong><a href="https://github.com/NVIDIA/pix2pixHD">pix2pixHD</a></strong>: 2048x1024 image synthesis with conditional GANs.</p>
<p class="content"><strong><a href="https://github.com/junyanz/BicycleGAN">BicycleGAN</a></strong>: multimodal image-to-image translation.</p>
<p class="content"><strong><a href="https://github.com/junyanz/interactive-deep-colorization">Interactive Deep Colorization</a></strong>:  real-time interface for user-guided colorization.</p>
<p class="content"><strong><a href="https://github.com/richzhang/colorization-pytorch">PyTorch Colorization</a></strong>: PyTorch code for training interactive colorization models.</p>
<p class="content"><strong><a href="https://github.com/junyanz/light-field-video">Light Field Video</a></strong>: light field video applications (e.g. video refocusing, changing aperture and view).</p>
<p class="content"><strong><a href="https://github.com/junyanz/CycleGAN">CycleGAN</a></strong>: Torch implementation for learning an image-to-image translation without input-output pairs.</p>
<p class="content"><strong><a href="https://github.com/phillipi/pix2pix">pix2pix</a></strong>: Torch implementation for learning a mapping from input images to output images.</p>
<p class="content"><strong><a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix">pytorch CycleGAN & pix2pix</a></strong>: PyTorch implementation for both unpaired and paired image-to-image translation.</p>
<p class="content"><strong><a href="https://github.com/junyanz/iGAN">iGAN</a></strong>: a deep learning software that easily generates images with a few brushstrokes.</p>
<p class="content"><strong><a href="https://github.com/junyanz/RealismCNN">RealismCNN</a></strong>: code for predicting and improving visual realism in composite images.</p>
<p class="content"><strong><a href="https://github.com/junyanz/MCILBoost">MCILBoost</a></strong>: a boosting-based Multiple Instance Learning (MIL) software.</p>
<p class="content"><strong><a href="https://github.com/junyanz/MirrorMirror">MirrorMirror</a></strong>: an expression training App that helps users mimic their own expressions.</p>
<p class="content"><strong><a href="https://github.com/junyanz/SelectGoodFace">SelectGoodFace</a></strong>: a program for selecting attractive/serious portraits from a personal photo collection.</p>
<p class="content"><strong><a href="https://github.com/junyanz/FaceDemo">FaceDemo</a></strong>: a simple 3D face alignment and warping demo.</p>
-->

<!--
<br>
<p id="sect-talks" class="title-large">Talks</p>
<p class="content"><strong><a href="https://youtu.be/MkluiD2lYCc?t=1h16m58s">Learning to Generate Images</a></strong></p>
<p class="content">SIGGRAPH Dissertation Award Talk (2018)</p>

<p class="content"><strong><a href="http://efrosgans.eecs.berkeley.edu/CVPR18_slides/CycleGAN.pptx">Unpaired Image-to-Image Translation</a></strong></p>
<p class="content">CVPR Tutorial on GANs (2018)</p>

<p class="content"><strong><a href="talks/talk_natural_photos.pptx">Learning to Synthesize and Manipulate Natural Photos</a></strong></p>
<p class="content">MIT CSAIL, HKUST CSE Departmental Seminar, ICCV Tutorial on GANs, O'Reilly AI, AI with the best, Y Conf, DEVIEW, ODSC West (2017)</p>

<p class="content"><strong><a href="talks/image_translation.pptx">On Image-to-Image Translation</a></strong></p>
<p class="content">Stanford, MIT CSAIL, Facebook, CUHK, SNU (2017)</p>

<p class="content"><strong><a href="talks/ideepcolor.pptx">Interactive Deep Colorization</a></strong></p>
<p class="content">SIGGRAPH, NVIDIA Innovation Theater, Global AI Hackathon (2017)</p>

<p class="content"><strong><a href="talks/manipulation_synthesis_junyanz.pptx">Visual Manipulation and Synthesis on the Natural Image Manifold</a></strong></p>
<p class="content">Facebook, MSR, Berkeley BAIR, THU, ICML workshop "Visualization for Deep Learning" (2016)</p>

<p class="content"><strong><a href="http://efrosprojects.eecs.berkeley.edu/mirrormirror/mirrormirror_slides.pptx">Mirror Mirror: Crowdsourcing Better Portraits</a></strong></p>
<p class="content">SIGGRAPH Asia (2014)</p>
<p class="content"><strong><a href="talks/siga14_course_ddvc_junyanz.pdf">What Makes Big Visual Data Hard?</a></strong></p>
<p class="content">SIGGRAPH Asia invited course &quot;Data-Driven Visual Computing&quot; (2014)</p>
<p class="content"><strong><a href="http://efrosprojects.eecs.berkeley.edu/averageExplorer/averageExplorer_slides.pptx">AverageExplorer: Interactive Exploration and Alignment of Visual Data Collections</a></strong></p>
<p class="content">SIGGRAPH (2014)</p>
<p class="content"><strong><a href="talks/wsl_slides.pptx">Discovering Objects and Harvesting Visual Concepts via Weakly Supervised Learning</a></strong></p>
<p class="content"> Berkeley Visual Computing Lab (2014)</p>
<br>
-->

<p id="sect-talks" class="title-large">Academic Services</p></h3>
<p><li><font color="#000000" face="trebuchet ms, sans-serif" size="2" style="font-weight:norm">Associate Editors:</span></font></li></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000" face="trebuchet ms, sans-serif" size="1">KSII Transactions on Internet and Information Systems, since 2018</font></p>
<p><li><font color="#000000" face="trebuchet ms, sans-serif" size="2" style="font-weight:norm">Program Committee Member:</span></font></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000" face="trebuchet ms, sans-serif" size="1">Neural Information Processing Systems (NIPS), 2018</font></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000" face="trebuchet ms, sans-serif" size="1">International Conference on Computer Vision (ICCV), 2017</font></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000" face="trebuchet ms, sans-serif" size="1">ACM International Conference on Multimedia (MM: long paper, short paper), 2016-2018</font></p>
<p><li><font color="#000000" face="trebuchet ms, sans-serif" size="2" style="font-weight:norm">Reviewer for Journals:</span></font></li></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000" face="trebuchet ms, sans-serif" size="1">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</font>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000" face="trebuchet ms, sans-serif" size="1">IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</font></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000" face="trebuchet ms, sans-serif" size="1">ACM Transactions on Knowledge Discovery from Data (TKDD)</font></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000" face="trebuchet ms, sans-serif" size="1">IEEE Transactions on Knowledge and Data Engineering (TKDE)</font></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000" face="trebuchet ms, sans-serif" size="1">IEEE Transactions on Multimedia (TMM)</font></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000" face="trebuchet ms, sans-serif" size="1">IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</font></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000" face="trebuchet ms, sans-serif" size="1">Pattern Recognition- Elsevier</font></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000" face="trebuchet ms, sans-serif" size="1">Pattern Analysis and Applications - Springer</font></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000" face="trebuchet ms, sans-serif" size="1">Neurocomputing - Elsevier</font></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000" face="trebuchet ms, sans-serif" size="1">Multimedia Tools and Applications- Springer</font></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color="#000000" face="trebuchet ms, sans-serif" size="1">Pattern Recognition Letters - Elsevier</font></p>
<h3><a name="TOC-Links"></a><font face="trebuchet ms, sans-serif"></b>
</font></h3>

<p id="sect-talks" class="title-large">Links</p>
 <p class="margin-small">&nbsp;</p>
	   <p class="content">
     <strong><a href="https://sites.google.com/site/tangjh1981/">Jinhui Tang</a></strong> |
	 <strong><a href="http://www.eecs.ucf.edu/~gqi/">Guo-Jun Qi</a></strong>|
	 <strong><a href="	 https://www.ece.nus.edu.sg/stfpage/eleyans/">Shuicheng Yan</a></strong>|
	 <strong><a href="https://sites.google.com/site/zcliustc/">Zechao Li</a></strong> |
	 <strong><a href="http://research.microsoft.com/en-us/um/people/jingdw/">Jingdong Wang</a></strong> |
	 <strong><a href="http://www.yugangjiang.info/">Yu-Gang Jiang</a></strong> 	 
			<br>
		</p>



<!-- <p id="sect-misc" class="title-large">MISC</p>
<p class="content"><strong><a href="imgs/pet.JPG">Photo</a></strong> of my cat Aquarius and my dog Arya.</p> -->

<div style="display:none">
<!-- GoStats JavaScript Based Code -->
<script type="text/javascript" src="http://gostats.com/js/counter.js"></script>
<script type="text/javascript">_gos='c3.gostats.com';_goa=390583;
_got=4;_goi=1;_goz=0;_god='hits';_gol='web page statistics from GoStats';_GoStatsRun();</script>
<a target="_blank" title="web page statistics from GoStats"
href="http://gostats.com"> 
</div>
<!--
<img alt="web page statistics from GoStats"
src="http://c3.gostats.com/bin/count/a_390583/t_4/i_1/z_0/show_hits/counter.png"
style="border-width:0" />

</a>

-->
<!-- End GoStats JavaScript Based Code -->
<br>
<a href="https://clustrmaps.com/site/1ae97"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=smLHFfsmfjs8fmCSuzoHueDWPzeRXLdL4ztDyhrhmSw&cl=ffffff" /></a>

</body></html>
